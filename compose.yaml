version: "3.8"

services:
    selenium:
        image: seleniarm/standalone-chromium:latest
        container_name: selenium
        # environment:
        #     - DISPLAY=host.docker.internal:0
        ports:
            - "4444:4444"
        shm_size: "2g"
        healthcheck:
            test: ["CMD", "curl", "-f", "https://www.edgeprop.sg/condo-apartment/the-lakeshore"]
            interval: 30s
            timeout: 10s
            retries: 3
    scraper:
        build:
            context: .
            dockerfile: Dockerfile
        container_name: scraper
        volumes:
            - .:/app
            - ./data:/app/data  # Persist dataframes saved to Excel here
        depends_on:
            - selenium
        environment:
            - SELENIUM_HOST=selenium
            - SELENIUM_PORT=4444
            - URL_SUFFIXES=parc-vista,the-lakeshore,caspian,lakeholmz
            - DEBUGPY=0  # Set to 1 to enable debugger wait in scraper.py
        ports:
            - "8080:8080"
            - "5678:5678"
